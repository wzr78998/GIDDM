

# GIDDM: Hyperspectral Image Domain Adaptation Project  

## ğŸ“‹ Project Overview  

This is the implementation of the paper **GIDDM**:  
**GIDDM: Generating Labels with Diffusion Model to Promote Cross-domain Open-set Image Recognition**  

## âœ¨ Main Features  

- ğŸš€ Supports multiple hyperspectral datasets (Houston, Pavia, etc.)  
- ğŸ¯ Optimized data processing pipeline for the characteristics of hyperspectral images  
- ğŸ“ˆ Complete training and evaluation framework  

## ğŸ› ï¸ Environment Requirements  

| Dependency | Version Requirement |
|------------|---------------------|
| Python     | 3.6+                |
| PyTorch    | 1.7+                |
| CUDA       | 10.0+ (Optional, for GPU acceleration) |
| Other dependencies | See `requirements.txt` |

## ğŸ“¦ Installation Instructions  

### 1. Clone the Project  
```bash
git clone [project_url]
cd GIDDM
```

### 2. Install Dependencies  
```bash
pip install -r requirements.txt
```

### 3. Prepare the Dataset  
- Place dataset files in the `data/` directory  
- Ensure the data format meets the requirements (`.mat` files)  

## ğŸ“š Dataset Preparation  

### Supported Datasets  

#### ğŸ™ï¸ Houston Dataset  
| Item         | Details              |
|--------------|----------------------|
| **Source**   | `Houston13.mat`      |
| **Target**   | `Houston18.mat`      |
| **Training Script** | `train_HS.py` |

#### ğŸ›ï¸ Pavia Dataset  
| Item         | Details              |
|--------------|----------------------|
| **Source**   | `paviaC.mat`         |
| **Target**   | `paviaU.mat`         |
| **Training Script** | `train-Pavia.py` |

### ğŸ“‹ Data Format Requirements  

- âœ… Data files should be in `.mat` format  
- âœ… Label files should contain the corresponding ground truth information  
- âœ… Data should be organized according to the specified directory structure  

## ğŸš€ Usage  

### Basic Training Commands  

#### Train on Houston Dataset  
```bash
python train_HS.py
```

#### Train on Pavia Dataset  
```bash
python train-Pavia.py
```

### Configuration Parameters  

The main configuration parameters are defined in the `config_HSI_PCPU.py` file:  

#### ğŸ“Š Data-level Parameters  
| Parameter         | Description                | Example Value           |
|-------------------|----------------------------|-------------------------|
| `--dataset`       | Dataset name               | Houston, Pavia          |
| `--target_domain` | Target domain name          | Houston18, paviaU       |  

### Training Examples  

#### ğŸ¯ Standard Training  
```bash
# Pavia Dataset
python train-Pavia.py

# Houston Dataset
python train_HS.py
```

### ğŸ”„ Model Training Workflow  

```mermaid
1. **ğŸ“¥ Data Loading**: Load source domain and target domain data from the specified path  
2. **ğŸ”§ Data Preprocessing**: Perform label mapping and data augmentation  
3. **ğŸ—ï¸ Model Construction**: Initialize the GIDDM model  
4. **âš™ï¸ Training Initialization**: Set training parameters and optimizer  
5. **ğŸš€ Model Training**: Execute domain adaptation training  
6. **ğŸ’¾ Save Results**: Save training results and models  
```

## ğŸ“ Project Structure  

```
GIDDM/
â”œâ”€â”€ ğŸ“„ config_HSI_PCPU.py          # Configuration file
â”œâ”€â”€ ğŸ train_HS.py                 # Houston dataset training script
â”œâ”€â”€ ğŸ train-Pavia.py              # Pavia dataset training script
â”œâ”€â”€ ğŸ§  models/                     # Model definitions
â”‚   â”œâ”€â”€ model_PCPU_HSI.py         # GIDDM model implementation
â”‚   â”œâ”€â”€ model_HSI_HS.py           # HSI model implementation
â”‚   â”œâ”€â”€ basenet.py                # Base network
â”‚   â””â”€â”€ function.py                # Utility functions
â”œâ”€â”€ ğŸ“Š data_loader/                # Data loaders
â”‚   â”œâ”€â”€ get_loader.py             # Data loading interface
â”‚   â”œâ”€â”€ mydataset.py              # Dataset class
â”‚   â””â”€â”€ base.py                   # Base dataset class
â”œâ”€â”€ ğŸ“ data/                       # Dataset directory
â”‚   â”œâ”€â”€ Houston/                  # Houston dataset
â”‚   â”œâ”€â”€ Pavia/                    # Pavia dataset
â”‚   â”œâ”€â”€ KSC/                      # KSC dataset
â”‚   â””â”€â”€ office/                   # Office dataset
â”œâ”€â”€ ğŸ› ï¸ utils/                      # Utility functions
â”œâ”€â”€ ğŸ“ˆ results/                    # Results saving directory
â””â”€â”€ ğŸ“– README.md                   # Project documentation
```

## ğŸ“š Citation  

If you use this project in your research, please cite the related paper:  

```bibtex
[Related paper citation]
```

## ğŸ“„ License  

This project is released under the MIT License. See the LICENSE file for details.  

## ğŸ¤ Contributing  

Contributions are welcome via Issues and Pull Requests to improve the project!  

- ğŸ› Report bugs  
- ğŸ’¡ Suggest new features  
- ğŸ“ Improve documentation  
- ğŸ”§ Contribute code  

## ğŸ“ Contact  

If you have any questions, please contact:  

- ğŸ“§ Email: [wanghaoyucumt@163.com]  
- ğŸ™ GitHub Issues: [project_url]/issues  

---

<div align="center">

**â­ If you find this project useful, please give us a star! â­**

</div>  
